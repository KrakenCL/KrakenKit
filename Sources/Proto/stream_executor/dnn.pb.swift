// DO NOT EDIT.
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: tensorflow/stream_executor/dnn.proto
//
// For information on using the generated types, please see the documenation:
//   https://github.com/apple/swift-protobuf/

/// LINT: LEGACY_NAMES

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that your are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Specifies the data type used by an operation.
public enum StreamExecutor_Dnn_DataType: SwiftProtobuf.Enum {
  public typealias RawValue = Int
  case kFloat // = 0
  case kDouble // = 1
  case kHalf // = 2
  case kInt8 // = 3
  case kInt32 // = 4
  case UNRECOGNIZED(Int)

  public init() {
    self = .kFloat
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .kFloat
    case 1: self = .kDouble
    case 2: self = .kHalf
    case 3: self = .kInt8
    case 4: self = .kInt32
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .kFloat: return 0
    case .kDouble: return 1
    case .kHalf: return 2
    case .kInt8: return 3
    case .kInt32: return 4
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension StreamExecutor_Dnn_DataType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [StreamExecutor_Dnn_DataType] = [
    .kFloat,
    .kDouble,
    .kHalf,
    .kInt8,
    .kInt32,
  ]
}

#endif  // swift(>=4.2)

/// Describes how a convolution input or output layer's data is formatted.
public enum StreamExecutor_Dnn_DataLayout: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  /// Naming convention:
  /// Y <-> row or height
  /// X <-> column or width
  /// Batch <-> batch, or N
  /// Depth <-> feature, or channel
  /// TODO(timshen): turn them into cuDNN names, e.g. kNCHW.
  case kYxdepthBatch // = 0
  case kYxbatchDepth // = 1

  /// cuDNN's NHWC layout
  case kBatchYxdepth // = 2

  /// cuDNN's NCHW layout
  case kBatchDepthYx // = 3

  /// cuDNN's NCHW_VECT_C layout
  case kBatchDepthYx4 // = 4
  case UNRECOGNIZED(Int)

  public init() {
    self = .kYxdepthBatch
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .kYxdepthBatch
    case 1: self = .kYxbatchDepth
    case 2: self = .kBatchYxdepth
    case 3: self = .kBatchDepthYx
    case 4: self = .kBatchDepthYx4
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .kYxdepthBatch: return 0
    case .kYxbatchDepth: return 1
    case .kBatchYxdepth: return 2
    case .kBatchDepthYx: return 3
    case .kBatchDepthYx4: return 4
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension StreamExecutor_Dnn_DataLayout: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [StreamExecutor_Dnn_DataLayout] = [
    .kYxdepthBatch,
    .kYxbatchDepth,
    .kBatchYxdepth,
    .kBatchDepthYx,
    .kBatchDepthYx4,
  ]
}

#endif  // swift(>=4.2)

/// Describes how a convolution filter is laid out in the memory.
public enum StreamExecutor_Dnn_FilterLayout: SwiftProtobuf.Enum {
  public typealias RawValue = Int

  /// Naming convention:
  /// Y <-> row or height
  /// X <-> column or width
  /// Output <-> output feature, or N
  /// Input <-> input feature, or N
  /// TODO(timshen): turn them into cuDNN names, e.g. kNCHW.
  case kOutputInputYx // = 0

  /// cuDNN's NHWC layout
  case kOutputYxinput // = 1

  /// cuDNN's NCHW_VECT_C layout
  case kOutputInputYx4 // = 2
  case kInputYxoutput // = 3
  case kYxinputOutput // = 4
  case UNRECOGNIZED(Int)

  public init() {
    self = .kOutputInputYx
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .kOutputInputYx
    case 1: self = .kOutputYxinput
    case 2: self = .kOutputInputYx4
    case 3: self = .kInputYxoutput
    case 4: self = .kYxinputOutput
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .kOutputInputYx: return 0
    case .kOutputYxinput: return 1
    case .kOutputInputYx4: return 2
    case .kInputYxoutput: return 3
    case .kYxinputOutput: return 4
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension StreamExecutor_Dnn_FilterLayout: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [StreamExecutor_Dnn_FilterLayout] = [
    .kOutputInputYx,
    .kOutputYxinput,
    .kOutputInputYx4,
    .kInputYxoutput,
    .kYxinputOutput,
  ]
}

#endif  // swift(>=4.2)

/// Describes a kind of non-linearity (threshold-like mathematical function).
public enum StreamExecutor_Dnn_ActivationMode: SwiftProtobuf.Enum {
  public typealias RawValue = Int
  case kNone // = 0
  case kSigmoid // = 1

  /// Rectified linear activation: f(x) = x < 0 ? 0 : x
  case kRelu // = 2

  /// Rectified linear activation; where upper maximum is 6.0.
  case kRelu6 // = 3

  /// Rectified linear activation; where upper maximum specified by
  /// BatchDescriptor::value_max().
  case kReluX // = 4
  case kTanh // = 5

  /// Like ReluX; but passes all values in the range [-X,X].
  case kBandPass // = 6
  case UNRECOGNIZED(Int)

  public init() {
    self = .kNone
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .kNone
    case 1: self = .kSigmoid
    case 2: self = .kRelu
    case 3: self = .kRelu6
    case 4: self = .kReluX
    case 5: self = .kTanh
    case 6: self = .kBandPass
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .kNone: return 0
    case .kSigmoid: return 1
    case .kRelu: return 2
    case .kRelu6: return 3
    case .kReluX: return 4
    case .kTanh: return 5
    case .kBandPass: return 6
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension StreamExecutor_Dnn_ActivationMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [StreamExecutor_Dnn_ActivationMode] = [
    .kNone,
    .kSigmoid,
    .kRelu,
    .kRelu6,
    .kReluX,
    .kTanh,
    .kBandPass,
  ]
}

#endif  // swift(>=4.2)

/// Describe the math definition for the conv op. The popular behavior is
/// actually called cross-correlation in math, despite the operation is often
/// referred as convolution. See cuDNN cudnnConvolutionMode_t.
public enum StreamExecutor_Dnn_ConvolutionMode: SwiftProtobuf.Enum {
  public typealias RawValue = Int
  case crossCorrelation // = 0
  case convolution // = 1
  case UNRECOGNIZED(Int)

  public init() {
    self = .crossCorrelation
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .crossCorrelation
    case 1: self = .convolution
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .crossCorrelation: return 0
    case .convolution: return 1
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension StreamExecutor_Dnn_ConvolutionMode: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [StreamExecutor_Dnn_ConvolutionMode] = [
    .crossCorrelation,
    .convolution,
  ]
}

#endif  // swift(>=4.2)

public enum StreamExecutor_Dnn_ConvolutionKind: SwiftProtobuf.Enum {
  public typealias RawValue = Int
  case invalid // = 0
  case forward // = 1
  case backwardFilter // = 2
  case backwardData // = 3
  case UNRECOGNIZED(Int)

  public init() {
    self = .invalid
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .invalid
    case 1: self = .forward
    case 2: self = .backwardFilter
    case 3: self = .backwardData
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .invalid: return 0
    case .forward: return 1
    case .backwardFilter: return 2
    case .backwardData: return 3
    case .UNRECOGNIZED(let i): return i
    }
  }

}

#if swift(>=4.2)

extension StreamExecutor_Dnn_ConvolutionKind: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [StreamExecutor_Dnn_ConvolutionKind] = [
    .invalid,
    .forward,
    .backwardFilter,
    .backwardData,
  ]
}

#endif  // swift(>=4.2)

/// Generic tensor representation.
public struct StreamExecutor_Dnn_TensorDescriptorProto {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var dimensions: [Int64] = []

  public var dataType: StreamExecutor_Dnn_DataType = .kFloat

  public var layoutOneof: StreamExecutor_Dnn_TensorDescriptorProto.OneOf_LayoutOneof? = nil

  public var dataLayout: StreamExecutor_Dnn_DataLayout {
    get {
      if case .dataLayout(let v)? = layoutOneof {return v}
      return .kYxdepthBatch
    }
    set {layoutOneof = .dataLayout(newValue)}
  }

  public var filterLayout: StreamExecutor_Dnn_FilterLayout {
    get {
      if case .filterLayout(let v)? = layoutOneof {return v}
      return .kOutputInputYx
    }
    set {layoutOneof = .filterLayout(newValue)}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public enum OneOf_LayoutOneof: Equatable {
    case dataLayout(StreamExecutor_Dnn_DataLayout)
    case filterLayout(StreamExecutor_Dnn_FilterLayout)

  #if !swift(>=4.1)
    public static func ==(lhs: StreamExecutor_Dnn_TensorDescriptorProto.OneOf_LayoutOneof, rhs: StreamExecutor_Dnn_TensorDescriptorProto.OneOf_LayoutOneof) -> Bool {
      switch (lhs, rhs) {
      case (.dataLayout(let l), .dataLayout(let r)): return l == r
      case (.filterLayout(let l), .filterLayout(let r)): return l == r
      default: return false
      }
    }
  #endif
  }

  public init() {}
}

/// Generic algorithm representation.
public struct StreamExecutor_Dnn_AlgorithmProto {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var algoID: Int64 = 0

  public var mathType: StreamExecutor_Dnn_AlgorithmProto.MathType = .defaultMath

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public enum MathType: SwiftProtobuf.Enum {
    public typealias RawValue = Int
    case defaultMath // = 0

    /// The GPU may operate 4x4 matrix FMA.
    /// See cuDNN's documentation for CUDNN_TENSOR_OP_MATH.
    case tensorOpMath // = 1
    case UNRECOGNIZED(Int)

    public init() {
      self = .defaultMath
    }

    public init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .defaultMath
      case 1: self = .tensorOpMath
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    public var rawValue: Int {
      switch self {
      case .defaultMath: return 0
      case .tensorOpMath: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

  }

  public init() {}
}

#if swift(>=4.2)

extension StreamExecutor_Dnn_AlgorithmProto.MathType: CaseIterable {
  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static var allCases: [StreamExecutor_Dnn_AlgorithmProto.MathType] = [
    .defaultMath,
    .tensorOpMath,
  ]
}

#endif  // swift(>=4.2)

/// Convolution-specific parameters.
public struct StreamExecutor_Dnn_ConvolutionDescriptorProto {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var paddings: [Int64] = []

  public var strides: [Int64] = []

  public var dilations: [Int64] = []

  /// The "accumulator" type. For example, use F32 as an accumulator for F16
  /// convolutions.
  /// See cuDNN's cudnnConvolutionMode_t.
  public var computeMode: StreamExecutor_Dnn_DataType = .kFloat

  /// See cuDNN's group count.
  public var groupCount: Int32 = 0

  public var convolutionMode: StreamExecutor_Dnn_ConvolutionMode = .crossCorrelation

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

/// A convolution. Currently it's only used for logging. In the future, we may
/// want to use it in the API as well.
public struct StreamExecutor_Dnn_ConvolutionProto {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var kind: StreamExecutor_Dnn_ConvolutionKind {
    get {return _storage._kind}
    set {_uniqueStorage()._kind = newValue}
  }

  public var input: StreamExecutor_Dnn_TensorDescriptorProto {
    get {return _storage._input ?? StreamExecutor_Dnn_TensorDescriptorProto()}
    set {_uniqueStorage()._input = newValue}
  }
  /// Returns true if `input` has been explicitly set.
  public var hasInput: Bool {return _storage._input != nil}
  /// Clears the value of `input`. Subsequent reads from it will return its default value.
  public mutating func clearInput() {_uniqueStorage()._input = nil}

  public var filter: StreamExecutor_Dnn_TensorDescriptorProto {
    get {return _storage._filter ?? StreamExecutor_Dnn_TensorDescriptorProto()}
    set {_uniqueStorage()._filter = newValue}
  }
  /// Returns true if `filter` has been explicitly set.
  public var hasFilter: Bool {return _storage._filter != nil}
  /// Clears the value of `filter`. Subsequent reads from it will return its default value.
  public mutating func clearFilter() {_uniqueStorage()._filter = nil}

  public var output: StreamExecutor_Dnn_TensorDescriptorProto {
    get {return _storage._output ?? StreamExecutor_Dnn_TensorDescriptorProto()}
    set {_uniqueStorage()._output = newValue}
  }
  /// Returns true if `output` has been explicitly set.
  public var hasOutput: Bool {return _storage._output != nil}
  /// Clears the value of `output`. Subsequent reads from it will return its default value.
  public mutating func clearOutput() {_uniqueStorage()._output = nil}

  public var algorithm: StreamExecutor_Dnn_AlgorithmProto {
    get {return _storage._algorithm ?? StreamExecutor_Dnn_AlgorithmProto()}
    set {_uniqueStorage()._algorithm = newValue}
  }
  /// Returns true if `algorithm` has been explicitly set.
  public var hasAlgorithm: Bool {return _storage._algorithm != nil}
  /// Clears the value of `algorithm`. Subsequent reads from it will return its default value.
  public mutating func clearAlgorithm() {_uniqueStorage()._algorithm = nil}

  public var convDesc: StreamExecutor_Dnn_ConvolutionDescriptorProto {
    get {return _storage._convDesc ?? StreamExecutor_Dnn_ConvolutionDescriptorProto()}
    set {_uniqueStorage()._convDesc = newValue}
  }
  /// Returns true if `convDesc` has been explicitly set.
  public var hasConvDesc: Bool {return _storage._convDesc != nil}
  /// Clears the value of `convDesc`. Subsequent reads from it will return its default value.
  public mutating func clearConvDesc() {_uniqueStorage()._convDesc = nil}

  /// result = conv_scale * conv(...) + side_value_scale * side_value.
  /// side_value is an arbitrary buffer if activation is not none. Otherwise, it
  /// has to be the result buffer (using its old values).
  public var convScale: Double {
    get {return _storage._convScale}
    set {_uniqueStorage()._convScale = newValue}
  }

  public var sideValueScale: Double {
    get {return _storage._sideValueScale}
    set {_uniqueStorage()._sideValueScale = newValue}
  }

  public var activation: StreamExecutor_Dnn_ActivationMode {
    get {return _storage._activation}
    set {_uniqueStorage()._activation = newValue}
  }

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "stream_executor.dnn"

extension StreamExecutor_Dnn_DataType: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "kFloat"),
    1: .same(proto: "kDouble"),
    2: .same(proto: "kHalf"),
    3: .same(proto: "kInt8"),
    4: .same(proto: "kInt32"),
  ]
}

extension StreamExecutor_Dnn_DataLayout: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "kYXDepthBatch"),
    1: .same(proto: "kYXBatchDepth"),
    2: .same(proto: "kBatchYXDepth"),
    3: .same(proto: "kBatchDepthYX"),
    4: .same(proto: "kBatchDepthYX4"),
  ]
}

extension StreamExecutor_Dnn_FilterLayout: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "kOutputInputYX"),
    1: .same(proto: "kOutputYXInput"),
    2: .same(proto: "kOutputInputYX4"),
    3: .same(proto: "kInputYXOutput"),
    4: .same(proto: "kYXInputOutput"),
  ]
}

extension StreamExecutor_Dnn_ActivationMode: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "kNone"),
    1: .same(proto: "kSigmoid"),
    2: .same(proto: "kRelu"),
    3: .same(proto: "kRelu6"),
    4: .same(proto: "kReluX"),
    5: .same(proto: "kTanh"),
    6: .same(proto: "kBandPass"),
  ]
}

extension StreamExecutor_Dnn_ConvolutionMode: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "CROSS_CORRELATION"),
    1: .same(proto: "CONVOLUTION"),
  ]
}

extension StreamExecutor_Dnn_ConvolutionKind: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "INVALID"),
    1: .same(proto: "FORWARD"),
    2: .same(proto: "BACKWARD_FILTER"),
    3: .same(proto: "BACKWARD_DATA"),
  ]
}

extension StreamExecutor_Dnn_TensorDescriptorProto: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TensorDescriptorProto"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "dimensions"),
    2: .standard(proto: "data_type"),
    3: .standard(proto: "data_layout"),
    4: .standard(proto: "filter_layout"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeRepeatedInt64Field(value: &self.dimensions)
      case 2: try decoder.decodeSingularEnumField(value: &self.dataType)
      case 3:
        if self.layoutOneof != nil {try decoder.handleConflictingOneOf()}
        var v: StreamExecutor_Dnn_DataLayout?
        try decoder.decodeSingularEnumField(value: &v)
        if let v = v {self.layoutOneof = .dataLayout(v)}
      case 4:
        if self.layoutOneof != nil {try decoder.handleConflictingOneOf()}
        var v: StreamExecutor_Dnn_FilterLayout?
        try decoder.decodeSingularEnumField(value: &v)
        if let v = v {self.layoutOneof = .filterLayout(v)}
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.dimensions.isEmpty {
      try visitor.visitPackedInt64Field(value: self.dimensions, fieldNumber: 1)
    }
    if self.dataType != .kFloat {
      try visitor.visitSingularEnumField(value: self.dataType, fieldNumber: 2)
    }
    switch self.layoutOneof {
    case .dataLayout(let v)?:
      try visitor.visitSingularEnumField(value: v, fieldNumber: 3)
    case .filterLayout(let v)?:
      try visitor.visitSingularEnumField(value: v, fieldNumber: 4)
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: StreamExecutor_Dnn_TensorDescriptorProto, rhs: StreamExecutor_Dnn_TensorDescriptorProto) -> Bool {
    if lhs.dimensions != rhs.dimensions {return false}
    if lhs.dataType != rhs.dataType {return false}
    if lhs.layoutOneof != rhs.layoutOneof {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension StreamExecutor_Dnn_AlgorithmProto: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AlgorithmProto"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "algo_id"),
    2: .standard(proto: "math_type"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeSingularInt64Field(value: &self.algoID)
      case 2: try decoder.decodeSingularEnumField(value: &self.mathType)
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.algoID != 0 {
      try visitor.visitSingularInt64Field(value: self.algoID, fieldNumber: 1)
    }
    if self.mathType != .defaultMath {
      try visitor.visitSingularEnumField(value: self.mathType, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: StreamExecutor_Dnn_AlgorithmProto, rhs: StreamExecutor_Dnn_AlgorithmProto) -> Bool {
    if lhs.algoID != rhs.algoID {return false}
    if lhs.mathType != rhs.mathType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension StreamExecutor_Dnn_AlgorithmProto.MathType: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "DEFAULT_MATH"),
    1: .same(proto: "TENSOR_OP_MATH"),
  ]
}

extension StreamExecutor_Dnn_ConvolutionDescriptorProto: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ConvolutionDescriptorProto"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "paddings"),
    2: .same(proto: "strides"),
    3: .same(proto: "dilations"),
    4: .standard(proto: "compute_mode"),
    5: .standard(proto: "group_count"),
    6: .standard(proto: "convolution_mode"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      switch fieldNumber {
      case 1: try decoder.decodeRepeatedInt64Field(value: &self.paddings)
      case 2: try decoder.decodeRepeatedInt64Field(value: &self.strides)
      case 3: try decoder.decodeRepeatedInt64Field(value: &self.dilations)
      case 4: try decoder.decodeSingularEnumField(value: &self.computeMode)
      case 5: try decoder.decodeSingularInt32Field(value: &self.groupCount)
      case 6: try decoder.decodeSingularEnumField(value: &self.convolutionMode)
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.paddings.isEmpty {
      try visitor.visitPackedInt64Field(value: self.paddings, fieldNumber: 1)
    }
    if !self.strides.isEmpty {
      try visitor.visitPackedInt64Field(value: self.strides, fieldNumber: 2)
    }
    if !self.dilations.isEmpty {
      try visitor.visitPackedInt64Field(value: self.dilations, fieldNumber: 3)
    }
    if self.computeMode != .kFloat {
      try visitor.visitSingularEnumField(value: self.computeMode, fieldNumber: 4)
    }
    if self.groupCount != 0 {
      try visitor.visitSingularInt32Field(value: self.groupCount, fieldNumber: 5)
    }
    if self.convolutionMode != .crossCorrelation {
      try visitor.visitSingularEnumField(value: self.convolutionMode, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: StreamExecutor_Dnn_ConvolutionDescriptorProto, rhs: StreamExecutor_Dnn_ConvolutionDescriptorProto) -> Bool {
    if lhs.paddings != rhs.paddings {return false}
    if lhs.strides != rhs.strides {return false}
    if lhs.dilations != rhs.dilations {return false}
    if lhs.computeMode != rhs.computeMode {return false}
    if lhs.groupCount != rhs.groupCount {return false}
    if lhs.convolutionMode != rhs.convolutionMode {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension StreamExecutor_Dnn_ConvolutionProto: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ConvolutionProto"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "kind"),
    2: .same(proto: "input"),
    3: .same(proto: "filter"),
    4: .same(proto: "output"),
    5: .same(proto: "algorithm"),
    6: .standard(proto: "conv_desc"),
    7: .standard(proto: "conv_scale"),
    8: .standard(proto: "side_value_scale"),
    9: .same(proto: "activation"),
  ]

  fileprivate class _StorageClass {
    var _kind: StreamExecutor_Dnn_ConvolutionKind = .invalid
    var _input: StreamExecutor_Dnn_TensorDescriptorProto? = nil
    var _filter: StreamExecutor_Dnn_TensorDescriptorProto? = nil
    var _output: StreamExecutor_Dnn_TensorDescriptorProto? = nil
    var _algorithm: StreamExecutor_Dnn_AlgorithmProto? = nil
    var _convDesc: StreamExecutor_Dnn_ConvolutionDescriptorProto? = nil
    var _convScale: Double = 0
    var _sideValueScale: Double = 0
    var _activation: StreamExecutor_Dnn_ActivationMode = .kNone

    static let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _kind = source._kind
      _input = source._input
      _filter = source._filter
      _output = source._output
      _algorithm = source._algorithm
      _convDesc = source._convDesc
      _convScale = source._convScale
      _sideValueScale = source._sideValueScale
      _activation = source._activation
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        switch fieldNumber {
        case 1: try decoder.decodeSingularEnumField(value: &_storage._kind)
        case 2: try decoder.decodeSingularMessageField(value: &_storage._input)
        case 3: try decoder.decodeSingularMessageField(value: &_storage._filter)
        case 4: try decoder.decodeSingularMessageField(value: &_storage._output)
        case 5: try decoder.decodeSingularMessageField(value: &_storage._algorithm)
        case 6: try decoder.decodeSingularMessageField(value: &_storage._convDesc)
        case 7: try decoder.decodeSingularDoubleField(value: &_storage._convScale)
        case 8: try decoder.decodeSingularDoubleField(value: &_storage._sideValueScale)
        case 9: try decoder.decodeSingularEnumField(value: &_storage._activation)
        default: break
        }
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      if _storage._kind != .invalid {
        try visitor.visitSingularEnumField(value: _storage._kind, fieldNumber: 1)
      }
      if let v = _storage._input {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }
      if let v = _storage._filter {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }
      if let v = _storage._output {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }
      if let v = _storage._algorithm {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      }
      if let v = _storage._convDesc {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      }
      if _storage._convScale != 0 {
        try visitor.visitSingularDoubleField(value: _storage._convScale, fieldNumber: 7)
      }
      if _storage._sideValueScale != 0 {
        try visitor.visitSingularDoubleField(value: _storage._sideValueScale, fieldNumber: 8)
      }
      if _storage._activation != .kNone {
        try visitor.visitSingularEnumField(value: _storage._activation, fieldNumber: 9)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: StreamExecutor_Dnn_ConvolutionProto, rhs: StreamExecutor_Dnn_ConvolutionProto) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._kind != rhs_storage._kind {return false}
        if _storage._input != rhs_storage._input {return false}
        if _storage._filter != rhs_storage._filter {return false}
        if _storage._output != rhs_storage._output {return false}
        if _storage._algorithm != rhs_storage._algorithm {return false}
        if _storage._convDesc != rhs_storage._convDesc {return false}
        if _storage._convScale != rhs_storage._convScale {return false}
        if _storage._sideValueScale != rhs_storage._sideValueScale {return false}
        if _storage._activation != rhs_storage._activation {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
